{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch_geometric"
      ],
      "metadata": {
        "id": "O9pv-8ncdrDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch_geometric.utils import from_networkx, negative_sampling\n",
        "from torch_geometric.nn import GCNConv, BatchNorm\n",
        "from torch.nn import Module"
      ],
      "metadata": {
        "id": "MTciIp-beVOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "id": "nC5XFRH60NH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/DANI.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "edges = [line.strip().split(',') for line in lines]\n",
        "edges_df = pd.DataFrame(edges, columns=['source', 'target'])\n",
        "edges_df = edges_df.astype(int)\n",
        "G = nx.from_pandas_edgelist(edges_df, source='source', target='target')\n",
        "\n",
        "with open('/content/cascades.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "num_nodes = edges_df.to_numpy().max() + 1\n",
        "num_features = len(lines)\n",
        "\n",
        "node_features = np.zeros((num_nodes, num_features))\n",
        "print(\"Shape of node_features:\", node_features.shape)\n",
        "\n",
        "for j, line in enumerate(lines):\n",
        "    entries = line.strip().split(';')\n",
        "    for entry in entries:\n",
        "        node_id, value = entry.split(',')\n",
        "        node_id = int(node_id)\n",
        "        value = float(value)\n",
        "        node_features[node_id, j] = value\n",
        "\n",
        "for node_id, features in enumerate(node_features):\n",
        "    G.nodes[node_id]['x'] = np.array(features, dtype=np.float32)\n",
        "\n",
        "\n",
        "with open('/content/community.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "labels = [list(map(int, l.strip().split())) for l in lines]\n",
        "print(\"Number of labels: \", len(labels))\n",
        "for label, nodes in enumerate(labels):\n",
        "  for node_id in nodes:\n",
        "      G.nodes[node_id]['y'] = label\n",
        "\n",
        "data = from_networkx(G)\n",
        "device = torch.device('cpu')\n",
        "data = data.to(device)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hef-jX_wm1oE",
        "outputId": "d70cc62f-b0dc-4164-e8b6-89d3c14d4c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of node_features: (1000, 20000)\n",
            "Number of labels:  28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/convert.py:278: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  data_dict[key] = torch.as_tensor(value)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[1000, 20000], edge_index=[2, 15384], y=[1000])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering for Logistic Regression"
      ],
      "metadata": {
        "id": "SQgoLDhI48Ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_link_labels(pos_edge_index, neg_edge_index):\n",
        "    edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1).to(device)\n",
        "    labels = torch.cat([torch.ones(pos_edge_index.size(1)), torch.zeros(neg_edge_index.size(1))], dim=0).to(device)\n",
        "    return edge_index, labels\n",
        "\n",
        "def extract_features(X, edges):\n",
        "    node_features = []\n",
        "    for edge in edges:\n",
        "        u, v = edge\n",
        "        node_features.append(np.concatenate([X[u], X[v]]))\n",
        "    return np.array(node_features)\n",
        "\n",
        "\n",
        "X_train_positive_edges, X_test_positive_edges = train_test_split(data.edge_index.T, test_size=0.2, random_state=42)\n",
        "\n",
        "pos_edge_index = X_train_positive_edges.T\n",
        "neg_edge_index = negative_sampling(pos_edge_index, num_nodes=data.x.shape[0])\n",
        "X_train, y_train = get_link_labels(pos_edge_index, neg_edge_index)\n",
        "X_train_features = extract_features(data.x.numpy(), X_train.T)\n",
        "\n",
        "pos_edge_index = X_test_positive_edges.T\n",
        "neg_edge_index = negative_sampling(pos_edge_index, num_nodes=data.x.shape[0])\n",
        "X_test, y_test = get_link_labels(pos_edge_index, neg_edge_index)\n",
        "X_test_features = extract_features(data.x.numpy(), X_test.T)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_features = torch.tensor(scaler.fit_transform(X_train_features), dtype=torch.float32)\n",
        "X_test_features = torch.tensor(scaler.transform(X_test_features), dtype=torch.float32)"
      ],
      "metadata": {
        "id": "zlmBgyt45AhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "Yel2haaR0Upe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf3S_s2hddc6",
        "outputId": "eecfe465-74ca-4cb0-f5c9-cdf7de92cedd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 1.1703\n",
            "Epoch [20/50], Loss: 0.7358\n",
            "Epoch [30/50], Loss: 0.6740\n",
            "Epoch [40/50], Loss: 0.6330\n",
            "Epoch [50/50], Loss: 0.6120\n",
            "\n",
            "Train Accuracy: 0.6708\n",
            "Train AUC: 0.7379\n",
            "Train F1 Score: 0.6579\n",
            "\n",
            "Test Accuracy: 0.6493\n",
            "Test AUC: 0.7130\n",
            "Test F1 Score: 0.6293\n"
          ]
        }
      ],
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.linear(x))\n",
        "\n",
        "\n",
        "model = LogisticRegression(X_train_features.shape[1])\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_features)\n",
        "    outputs = outputs.squeeze()\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    train_outputs = model(X_train_features)\n",
        "    test_outputs = model(X_test_features)\n",
        "\n",
        "train_predicted = (train_outputs > 0.5).float()\n",
        "test_predicted = (test_outputs > 0.5).float()\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, train_predicted)\n",
        "test_accuracy = accuracy_score(y_test, test_predicted)\n",
        "\n",
        "train_auc = roc_auc_score(y_train, train_outputs)\n",
        "test_auc = roc_auc_score(y_test, test_outputs)\n",
        "\n",
        "train_f1 = f1_score(y_train, train_predicted)\n",
        "test_f1 = f1_score(y_test, test_predicted)\n",
        "\n",
        "print(f'\\nTrain Accuracy: {train_accuracy:.4f}')\n",
        "print(f'Train AUC: {train_auc:.4f}')\n",
        "print(f'Train F1 Score: {train_f1:.4f}')\n",
        "print(f'\\nTest Accuracy: {test_accuracy:.4f}')\n",
        "print(f'Test AUC: {test_auc:.4f}')\n",
        "print(f'Test F1 Score: {test_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Distillation"
      ],
      "metadata": {
        "id": "rMQtDr0JmKsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directory = '/content/'\n",
        "path = None\n",
        "\n",
        "for root, dirs, files in os.walk(directory):\n",
        "    for file in files:\n",
        "        if file.endswith('.pth'):\n",
        "            path = os.path.join(root, file)\n",
        "            break\n",
        "    if path:\n",
        "        break"
      ],
      "metadata": {
        "id": "gY4ANNhcy_ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(Module):\n",
        "    def __init__(self, num_features, hidden_channels, out_channels, dropout=0.5):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "        self.conv4 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv4(x, edge_index)\n",
        "        return x\n",
        "\n",
        "    def link_logits(self, x, edge_index):\n",
        "        return (x[edge_index[0]] * x[edge_index[1]]).sum(dim=-1)\n"
      ],
      "metadata": {
        "id": "vXZGsvNydks6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = GCN(num_features=data.x.shape[1], hidden_channels=128, out_channels=64, dropout=0.5).to(device)\n",
        "checkpoint = torch.load(path)\n",
        "teacher_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "teacher_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gZI_lJWpI_k",
        "outputId": "cd47275f-bc35-4288-ab28-05c2453c909e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GCN(\n",
              "  (conv1): GCNConv(20000, 128)\n",
              "  (bn1): BatchNorm(128)\n",
              "  (conv2): GCNConv(128, 128)\n",
              "  (bn2): BatchNorm(128)\n",
              "  (conv3): GCNConv(128, 128)\n",
              "  (bn3): BatchNorm(128)\n",
              "  (conv4): GCNConv(128, 64)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_params = lambda x : sum(p.numel() for p in x.parameters())\n",
        "X_train_features_tensor = torch.FloatTensor(X_train_features)\n",
        "X_test_features_tensor = torch.FloatTensor(X_test_features)"
      ],
      "metadata": {
        "id": "fwW1mCaw64nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "temperature = 1.0\n",
        "alpha = 0.6\n",
        "num_epochs = 100\n",
        "\n",
        "student_model = LogisticRegression(X_train_features.shape[1])\n",
        "optimizer = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
        "criterion = nn.KLDivLoss(reduction='batchmean')\n",
        "# criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        teacher_output = teacher_model(data.x, X_train_positive_edges.T)\n",
        "        teacher_output = teacher_model.link_logits(teacher_output, X_train)\n",
        "        teacher_output = torch.sigmoid(teacher_output / temperature)\n",
        "\n",
        "    student_output = student_model(X_train_features_tensor).view(-1)\n",
        "    student_output_sigmoid = torch.sigmoid(student_output / temperature)\n",
        "\n",
        "    student_output_sigmoid = torch.clamp(student_output_sigmoid, min=1e-7, max=1.0 - 1e-7)\n",
        "\n",
        "    distillation_loss = criterion(student_output_sigmoid.log(), teacher_output)\n",
        "\n",
        "    ce_loss = F.binary_cross_entropy_with_logits(student_output, y_train.float())\n",
        "\n",
        "    loss = (1 - alpha) * ce_loss + alpha * distillation_loss\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], CE Loss: {ce_loss.item():.4f}, Distillation Loss: {distillation_loss.item():.4f}')\n",
        "\n",
        "\n",
        "student_model.eval()\n",
        "with torch.no_grad():\n",
        "    student_logits = student_model(X_test_features_tensor).view(-1)\n",
        "    student_probs = torch.sigmoid(student_logits)\n",
        "    student_predictions = (student_probs > 0.5).float()\n",
        "\n",
        "accuracy_student = torch.sum(student_predictions == y_test.float()).item() / len(y_test)\n",
        "y_test_np = y_test.cpu().numpy()\n",
        "student_probs_np = student_probs.cpu().numpy()\n",
        "student_predictions_np = student_predictions.cpu().numpy()\n",
        "\n",
        "auc_student = roc_auc_score(y_test_np, student_probs_np)\n",
        "f1_student = f1_score(y_test_np, student_predictions_np)\n",
        "\n",
        "print('\\nStudent Model Evaluation')\n",
        "print(f'Student Model Accuracy on Test Set: {accuracy_student:.4f}')\n",
        "print(f'Student Model AUC on Test Set: {auc_student:.4f}')\n",
        "print(f'Student Model F1-Score on Test Set: {f1_student:.4f}')\n",
        "\n",
        "\n",
        "teacher_model.eval()\n",
        "with torch.no_grad():\n",
        "    teacher_output = teacher_model(data.x, X_train_positive_edges.T)\n",
        "    teacher_logits = teacher_model.link_logits(teacher_output, X_test)\n",
        "    teacher_probs = torch.sigmoid(teacher_logits)\n",
        "    teacher_predictions = (teacher_probs > 0.5).float()\n",
        "\n",
        "accuracy_teacher = torch.sum(teacher_predictions == y_test.float()).item() / len(y_test)\n",
        "teacher_probs_np = teacher_probs.cpu().numpy()\n",
        "teacher_predictions_np = teacher_predictions.cpu().numpy()\n",
        "\n",
        "auc_teacher = roc_auc_score(y_test_np, teacher_probs_np)\n",
        "f1_teacher = f1_score(y_test_np, teacher_predictions_np)\n",
        "\n",
        "print('\\nTeacher Model Evaluation')\n",
        "print(f'Teacher Model Accuracy on Test Set: {accuracy_teacher:.4f}')\n",
        "print(f'Teacher Model AUC on Test Set: {auc_teacher:.4f}')\n",
        "print(f'Teacher Model F1-Score on Test Set: {f1_teacher:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8hFQ1ayNBe6",
        "outputId": "321e631c-f994-41d7-fa3a-5f0d2691ac1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], CE Loss: 0.8542, Distillation Loss: 0.5457\n",
            "Epoch [20/100], CE Loss: 0.8682, Distillation Loss: 0.4788\n",
            "Epoch [30/100], CE Loss: 0.6653, Distillation Loss: 0.3589\n",
            "Epoch [40/100], CE Loss: 0.6315, Distillation Loss: 0.3026\n",
            "Epoch [50/100], CE Loss: 0.6231, Distillation Loss: 0.2946\n",
            "Epoch [60/100], CE Loss: 0.6254, Distillation Loss: 0.2768\n",
            "Epoch [70/100], CE Loss: 0.6160, Distillation Loss: 0.2709\n",
            "Epoch [80/100], CE Loss: 0.6166, Distillation Loss: 0.2661\n",
            "Epoch [90/100], CE Loss: 0.6170, Distillation Loss: 0.2626\n",
            "Epoch [100/100], CE Loss: 0.6165, Distillation Loss: 0.2594\n",
            "\n",
            "Student Model Evaluation\n",
            "Student Model Accuracy on Test Set: 0.6685\n",
            "Student Model AUC on Test Set: 0.7203\n",
            "Student Model F1-Score on Test Set: 0.6761\n",
            "\n",
            "Teacher Model Evaluation\n",
            "Teacher Model Accuracy on Test Set: 0.8006\n",
            "Teacher Model AUC on Test Set: 0.9538\n",
            "Teacher Model F1-Score on Test Set: 0.8287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_params(teacher_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTndt8uO6h7-",
        "outputId": "0396a63f-9d9f-45e8-e4a1-b7bda5ba6a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2602176"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_params(student_model)"
      ],
      "metadata": {
        "id": "uLgnfdOaFFtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a477c7-be41-4798-d101-d27ea682eb2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40001"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Performance"
      ],
      "metadata": {
        "id": "GXXUOW-4O3X0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1=256, hidden_dim2=128, hidden_dim3=64):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
        "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dim2)\n",
        "        self.fc3 = nn.Linear(hidden_dim2, hidden_dim3)\n",
        "        self.bn3 = nn.BatchNorm1d(hidden_dim3)\n",
        "        self.fc4 = nn.Linear(hidden_dim3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = F.relu(self.bn3(self.fc3(x)))\n",
        "        return torch.sigmoid(self.fc4(x))\n",
        "\n",
        "\n",
        "\n",
        "model = MLP(X_train_features.shape[1])\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_features)\n",
        "    outputs = outputs.squeeze()\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    train_outputs = model(X_train_features)\n",
        "    test_outputs = model(X_test_features)\n",
        "\n",
        "train_predicted = (train_outputs > 0.5).float()\n",
        "test_predicted = (test_outputs > 0.5).float()\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, train_predicted)\n",
        "test_accuracy = accuracy_score(y_test, test_predicted)\n",
        "\n",
        "train_auc = roc_auc_score(y_train, train_outputs)\n",
        "test_auc = roc_auc_score(y_test, test_outputs)\n",
        "\n",
        "train_f1 = f1_score(y_train, train_predicted)\n",
        "test_f1 = f1_score(y_test, test_predicted)\n",
        "\n",
        "print(f'\\nTrain Accuracy: {train_accuracy:.4f}')\n",
        "print(f'Train AUC: {train_auc:.4f}')\n",
        "print(f'Train F1 Score: {train_f1:.4f}')\n",
        "print(f'\\nTest Accuracy: {test_accuracy:.4f}')\n",
        "print(f'Test AUC: {test_auc:.4f}')\n",
        "print(f'Test F1 Score: {test_f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWG5GzxKB0eL",
        "outputId": "894e2f79-d4df-4f05-e096-fd88c0fb051a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 0.6174\n",
            "Epoch [20/50], Loss: 0.6013\n",
            "Epoch [30/50], Loss: 0.5922\n",
            "Epoch [40/50], Loss: 0.5823\n",
            "Epoch [50/50], Loss: 0.5645\n",
            "\n",
            "Train Accuracy: 0.6417\n",
            "Train AUC: 0.7677\n",
            "Train F1 Score: 0.7246\n",
            "\n",
            "Test Accuracy: 0.6341\n",
            "Test AUC: 0.7041\n",
            "Test F1 Score: 0.7186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_params(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7n_SYUgGGaV",
        "outputId": "6e92eff4-2637-4cff-e5c3-de803bf54297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10282369"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "dxxrdJMdMAxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_model = GCN(num_features=data.x.shape[1], hidden_channels=64)\n",
        "count_params(example_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4mG0IgMagKP",
        "outputId": "83f237dc-32c7-4313-ff2d-7e76ad4fbd2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1292544"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P99MLrVLbBZ0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}